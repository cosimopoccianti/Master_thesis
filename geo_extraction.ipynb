{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo-spatial analysis\n",
    "\n",
    "The objective of this section is to extract geographical information about the papers. \n",
    "Initially, an attempt was made to search for information on the country of the authors' affiliation of various papers, but two problems were found:\n",
    "- Information regarding affiliation is available for a small number of authors\n",
    "- even when available, the affiliation is only one, thus not taking into account the authors' affiliation records, which can obviously lead to an error in the geographical classification of the paper.\n",
    "\n",
    "The abstracts were then searched for geographical references on the subject of the papers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import numpy as np\n",
    "import warnings\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeopyError\n",
    "import time\n",
    "import string\n",
    "import pycountry_convert as pc\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv loading\n",
    "df = pd.read_csv('Dataset_API/papers_shortlisted_final2.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors' affiliation\n",
    "\n",
    "Checking how many information are there in the dataset regardin authors affiliaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Affiliaton_info'] = 0\n",
    "authors_info = []\n",
    "for i in range(len(df)):\n",
    "    a = eval(df['authors'][i])\n",
    "    for j in range(len(a)):\n",
    "        authors_info.append(a[j])\n",
    "        if a[j]['affiliatons'] != None:\n",
    "            df['Affiliaton_info'][i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of papers with at least one affiliation: ', len(df[df['Affiliaton_info'] == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographical information search in abstracts\n",
    "\n",
    "Since information on affiliations are not sufficient, a search is made for geographical information in the abstracts. \n",
    "The first step is to make nlp on the abstracts, extracting information on locations in the texts, thanks to the spacy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the English nlp spacy library \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spacy library associates each word or group of words with a label representing whether they are sotantives, verbs, adjectives, etc. \n",
    "The label 'GPE' identifies countries, cities, states, while the label 'LOC' identifies Non-GPE locations, mountain ranges, bodies of water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing list of geo location found with spacy\n",
    "df['Geo'] = None\n",
    "for i in tqdm(range(len(df))):\n",
    "    doc = nlp(df['abstract'][i])\n",
    "    local = []\n",
    "    for w in doc.ents:\n",
    "        if w.label_ == 'LOC' or w.label_ == 'GPE':\n",
    "            local.append(w.text)\n",
    "    if local != []:\n",
    "        local_nop = []\n",
    "        for j in local:\n",
    "            local_nop.append(j.translate(str.maketrans('', '', string.punctuation)))\n",
    "        df['Geo'][i] = local_nop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percentage of papers with geospatial information in the abstract: ',round((len(df)-df['Geo'].isnull().sum())/len(df)*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkpoint\n",
    "df.to_csv('df_geo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function useful later used in combination with geopy, to save only information about the country of every location\n",
    "def get_last_word(phrase):\n",
    "    last_comma_index = phrase.rfind(',')\n",
    "    return phrase[last_comma_index + 1:].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the open access Nominatim as geolocator\n",
    "geolocator = Nominatim(user_agent='User', timeout=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function that returns the address of each location found using spaCy or an error if the location cannot be identified with Nominatim. \n",
    "Since Nominatim has a rate limiter, the function will pause for a few seconds when it encounters exceptions and then attempt to retrieve the address again. \n",
    "If it fails after five attempts, the function will return the location for which it encountered the failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_geocode(address, attempt=1, max_attempts=5):\n",
    "    try:\n",
    "        location = geolocator.geocode(address, language='en')\n",
    "        stringa = None\n",
    "        return location, stringa\n",
    "    except GeopyError:\n",
    "        if attempt <= max_attempts:\n",
    "            time.sleep(1.1)\n",
    "            return do_geocode(address, attempt=attempt+1)\n",
    "        elif attempt > max_attempts:\n",
    "            location = 'Not Available'\n",
    "            stringa = f'request failed for {address}'\n",
    "            return location, stringa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, the geopy library is used to gather information on the country of reference of the various locations identified earlier. In this case, a free API is used that relies on OpenStreetMap, and together with the names allows the coordinates to be retrieved. However, it tolerates continuous and repetitive requests poorly. For this reason, with each cycle, the location information is saved so that if the same location is found, the request to the API is not repeated, but the already saved data is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Country = {}\n",
    "Continent = {}\n",
    "Ocean = {}\n",
    "Sea = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_column = []\n",
    "lat_column = []\n",
    "lon_column = []\n",
    "\n",
    "for i in tqdm(df['Geo']):\n",
    "     if i != None:\n",
    "          loc_row = []\n",
    "          lat_row = []\n",
    "          lon_row = []\n",
    "          for j in np.unique(i):\n",
    "               if j not in Country and j not in Continent and j not in Ocean and j not in Sea:\n",
    "                    stringa= None\n",
    "                    location, stringa = do_geocode(j, attempt=1,max_attempts=5)\n",
    "                    if stringa:\n",
    "                         print(stringa)\n",
    "                    if location != None and location != 'Not Available':\n",
    "                         addresstype[location.raw['addresstype']] = 0\n",
    "                         loc_row.append(get_last_word(location.address))\n",
    "                         lat_row.append(location.latitude)\n",
    "                         lon_row.append(location.longitude)\n",
    "                         if location.raw['addresstype'] == 'continent':\n",
    "                              Continent[j] = {'loc' : get_last_word(location.address),\n",
    "                                              'lat' : location.latitude,\n",
    "                                              'lon' : location.longitude}\n",
    "                         elif location.raw['addresstype'] == 'ocean':\n",
    "                              Ocean[j] = {'loc' : get_last_word(location.address),\n",
    "                                              'lat' : location.latitude,\n",
    "                                              'lon' : location.longitude}\n",
    "                         elif location.raw['addresstype'] == 'sea':\n",
    "                              Sea[j] = {'loc' : get_last_word(location.address),\n",
    "                                              'lat' : location.latitude,\n",
    "                                              'lon' : location.longitude}\n",
    "                         else:\n",
    "                              Country[j] ={'loc' : get_last_word(location.address),\n",
    "                                              'lat' : location.latitude,\n",
    "                                              'lon' : location.longitude}\n",
    "                    else:\n",
    "                         loc_row.append(None)\n",
    "                         lat_row.append(None)\n",
    "                         lon_row.append(None)\n",
    "               elif j in Country:\n",
    "                    loc_row.append(Country[j]['loc'])\n",
    "                    lat_row.append(Country[j]['lat'])\n",
    "                    lon_row.append(Country[j]['lon'])\n",
    "               elif j in Continent:\n",
    "                    loc_row.append(Continent[j]['loc'])\n",
    "                    lat_row.append(Continent[j]['lat'])\n",
    "                    lon_row.append(Continent[j]['lon'])\n",
    "               elif j in Ocean:\n",
    "                    loc_row.append(Ocean[j]['loc'])\n",
    "                    lat_row.append(Ocean[j]['lat'])\n",
    "                    lon_row.append(Ocean[j]['lon'])\n",
    "               elif j in Sea:\n",
    "                    loc_row.append(Sea[j]['loc'])\n",
    "                    lat_row.append(Sea[j]['lat'])\n",
    "                    lon_row.append(Sea[j]['lon'])\n",
    "          loc_column.append(loc_row)\n",
    "          lat_column.append(lat_row)\n",
    "          lon_column.append(lon_row)\n",
    "     else:\n",
    "          loc_column.append(None)\n",
    "          lat_column.append(None)\n",
    "          lon_column.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attaching the information to the dataset\n",
    "df['location'] = loc_column\n",
    "df['latitude'] = lat_column\n",
    "df['longitude'] = lon_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint\n",
    "df.to_csv('df_geo_loc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_geo_loc.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the location column removing duplicated values for each entry\n",
    "loc_unique = []\n",
    "for i, lat, lon in tqdm(zip(df['location'], df['latitude'], df['longitude'])):\n",
    "    if pd.notna(i):\n",
    "        count = 0\n",
    "        for j in eval(i):\n",
    "            if j == None:\n",
    "                count += 1\n",
    "        if len(eval(i)) == count:\n",
    "            loc_unique.append(None)\n",
    "        else:\n",
    "            filtered_list = [item for item in eval(i) if item is not None]\n",
    "            loc_unique.append(list(np.unique(filtered_list)))\n",
    "    else:\n",
    "        loc_unique.append(None)\n",
    "df['country'] = loc_unique\n",
    "#Check the number of unique values\n",
    "unique_values_list = list(set(x for sublist in df['country'] if sublist is not None for x in sublist))\n",
    "len(unique_values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the address type of each location\n",
    "locations = {}\n",
    "add_type = []\n",
    "for i in tqdm(unique_values_list):\n",
    "    location, stringa = do_geocode(i, attempt=1,max_attempts=5)\n",
    "    if stringa:\n",
    "        print(stringa)\n",
    "    locations[i] = location.raw['addresstype']\n",
    "    add_type.append(location.raw['addresstype'])\n",
    "np.unique(add_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the results\n",
    "\n",
    "In the next section, the results are analysed, and manually, as the number of unique entries is not prohibitive, the places incorrectly classified for the purpose of the search are remapped. Specifically, there are marine places that can be associated with a specific country, and many places belonging to Antarctica, which geopy classifies individually and not at an aggregate level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_dict = {'Goguryeo Hill': 'Japan',\n",
    "    'Mount Gauss': 'Antarctica',\n",
    "    'Larsemann Hills': 'Antarctica',\n",
    "    'Mount Hancox': 'Antarctica',\n",
    "    'Mount Boreas': 'Antarctica',\n",
    "    'Brama': 'Antarctica',\n",
    "    'Grootes Peak': 'Antarctica',\n",
    "    'Dome Fuji': 'Antarctica',\n",
    "    'Utsteinen Nunatak': 'Antarctica',\n",
    "    'Waitt Peaks': 'Antarctica',\n",
    "    'Mount Palsson': 'Antarctica',\n",
    "    'Usnea Plug': 'Antarctica',\n",
    "    'Mayeda Peak': 'Antarctica',\n",
    "    'Northern Foothills': 'Antarctica',\n",
    "    'Anderson Nunataks': 'Antarctica',\n",
    "    'Allan Hills': 'Antarctica',\n",
    "    'The Gambia':'Gambia',\n",
    "    'Potter Peninsula': 'Antarctica',\n",
    "    'Byers Peninsula': 'Antarctica',\n",
    "    'Antarctic Peninsula': 'Antarctica',\n",
    "    'Sobral Peninsula': 'Antarctica',\n",
    "    'McMurdo Station': 'Antarctica',\n",
    "    'Aue': 'Germany',\n",
    "    'Congo-Brazzaville':'Congo',\n",
    "    'Villa Las Estrellas': 'Antarctica',\n",
    "    'Fountain Creek': 'United States',\n",
    "    'Aire': 'France',\n",
    "    'Mount Erebus': 'Antarctica',\n",
    "    'Cape Ross' : 'Philippines',\n",
    "    'North Foreland' : 'United Kingdom',\n",
    "    'Elk River' : 'Poland',\n",
    "    'Rybnitsa' : 'Moldova',\n",
    "    'Campbell Creek' : 'United States',\n",
    "    'Vechtaer Moorbach' : 'Germany',\n",
    "    'Poland contiguous zone': 'Poland',\n",
    "    'France (contiguous area in the Gulf of Biscay and west of English Channel)': 'France',\n",
    "    'France (contiguous area in the Mediterranean Sea)': 'France',\n",
    "    'South Pole' : 'Antarctica',\n",
    "    'Denmark Strait' : 'Denmark',\n",
    "    'Marsyangdi' : 'Nepal',\n",
    "    'East River' : 'United States',\n",
    "    'Natural Marine Park of the Gulf of Lion': 'France',\n",
    "    'Southeast Atlantic Seamounts Marine Protected Area': 'Atlantic Ocean',\n",
    "    'Área Marinha Protegida do MARNA': 'Atlantic Ocean',\n",
    "    'Adélie Land': 'Antarctica',\n",
    "    'West Antarctica': 'Antarctica',\n",
    "    'East Antarctica': 'Antarctica',\n",
    "    'Victoria Land': 'Antarctica',\n",
    "    'McMurdo Dry Valleys': 'Antarctica',\n",
    "    'The Fleet': 'United Kingdom',\n",
    "    'Bruchwetter': 'Germany',\n",
    "    \"Pugsley's Creek\": 'United States',\n",
    "    'Wrobel': 'Antarctica',\n",
    "    'Porter Brook': 'United Kingdom',\n",
    "    'Wissahickon Creek': 'United States',\n",
    "    'Lake Bonney': 'Antarctica',\n",
    "    'Lane Cove River': 'Australia',\n",
    "    'Patuxent River': 'United States',\n",
    "    'Lake Vanda': 'Antarctica',\n",
    "    'Castenholz Pond': 'Antarctica',\n",
    "    'Concordia Station': 'Antarctica',\n",
    "    'Rothera Research Station': 'Antarctica',\n",
    "    'Neumayer-Station III': 'Antarctica',\n",
    "    'Dome Fuji Station': 'Antarctica',\n",
    "    'West Antarctic Ice Sheet Divide': 'Antarctica',\n",
    "    'Transantarctic Mountains': 'Antarctica',\n",
    "    'Larsen C Ice Shelf' : 'Antarctica'\n",
    "     }\n",
    "\n",
    "to_drop = ['35000',\n",
    " '1086',\n",
    " '3962',\n",
    " '7262',\n",
    " 'Tar',\n",
    " 'Siple Dome',\n",
    " 'Pisonia'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remapping the wrong classified elements\n",
    "def replace_items(lst, mapping, values_to_drop):\n",
    "    if lst is not None:\n",
    "        updated_list = [mapping.get(item, item) for item in lst]\n",
    "        filtered_list = [item for item in updated_list if item not in values_to_drop]\n",
    "        return filtered_list\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['country_adj'] = df['country'].apply(lambda x: replace_items(x, repl_dict, to_drop))\n",
    "unique_values_list = list(set(x for sublist in df['country_adj'] if sublist is not None for x in sublist))\n",
    "len(unique_values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check again the address type\n",
    "locations = {}\n",
    "add_type = []\n",
    "for i in tqdm(unique_values_list):\n",
    "    location, stringa = do_geocode(i, attempt=1,max_attempts=5)\n",
    "    if stringa:\n",
    "        print(stringa)\n",
    "    locations[i] = location.raw['addresstype']\n",
    "    add_type.append(location.raw['addresstype'])\n",
    "np.unique(add_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict = {key: value for key, value in locations.items() if value == 'city'}\n",
    "filtered_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, the address types are remapped so that we only have an indication of whether the location is: a country, a continent, a gulf, a river, a sea or an ocean. For the latter, when these cannot be associated with a single nation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_addtype = {\n",
    "    'archipelago' : 'island',\n",
    "    'canal' : 'river',\n",
    "    'claimed_administrative' : 'country',\n",
    "    'islet' : 'island',\n",
    "    'land_area' : 'country',\n",
    "    'strait' : 'sea',\n",
    "    'water' : 'river',\n",
    "    'waterway' : 'river',\n",
    "    'locality' : 'continent',\n",
    "    'city' : 'country'\n",
    "}\n",
    "\n",
    "mapping_remaining = {\n",
    "    'Nicobar' : 'island',\n",
    "    'Rio Grande' : 'river',\n",
    "    'Andaman' : 'island'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving latitude and longitude of locations\n",
    "lat = {}\n",
    "lon = {}\n",
    "for i in tqdm(unique_values_list):\n",
    "    location, stringa = do_geocode(i, attempt=1,max_attempts=5)\n",
    "    if stringa:\n",
    "        print(stringa)\n",
    "    lat[i] = location.latitude\n",
    "    lon[i] = location.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving address type and coordinates for each location\n",
    "coord_col = []\n",
    "long_col = []\n",
    "add_type_col = []\n",
    "for i in tqdm(df['country_adj']):\n",
    "    if i != None:\n",
    "        coord = []\n",
    "        add_type_list = []\n",
    "        for j in i:\n",
    "            lat_values = lat[j] if isinstance(lat[j], (list, tuple)) else [lat[j]]\n",
    "            lon_values = lon[j] if isinstance(lon[j], (list, tuple)) else [lon[j]]\n",
    "            coord.extend(zip(lat_values,lon_values))\n",
    "            if j in mapping_remaining:\n",
    "                add_type_list.append(mapping_remaining[j])\n",
    "            elif locations[j] in mapping_addtype:\n",
    "                add_type_list.append(mapping_addtype[locations[j]])\n",
    "            else:\n",
    "                add_type_list.append(locations[j])\n",
    "        coord_col.append(coord)\n",
    "        add_type_col.append(add_type_list)\n",
    "    else:\n",
    "        coord_col.append(None)\n",
    "        add_type_col.append(None)\n",
    "\n",
    "df['coord_adj'] = coord_col\n",
    "df['add_type'] = add_type_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_list = list(set(x for sublist in df['add_type'] if sublist is not None for x in sublist))\n",
    "unique_values_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_type = []\n",
    "for i in df['add_type']:\n",
    "    if i != None:\n",
    "        for j in i:\n",
    "            add_type.append(j)\n",
    "keys_location, counts_locations = np.unique(add_type, return_counts=True)\n",
    "loc_counts = pd.DataFrame({'keys':keys_location,'counts':counts_locations})\n",
    "loc_counts = loc_counts.sort_values(by='counts', ascending=False)\n",
    "sns.barplot(data=loc_counts,x='counts',y='keys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = []\n",
    "for i,k in zip(df['add_type'],df['country_adj']):\n",
    "    if i != None:\n",
    "        for j,z in zip(i,k):\n",
    "            if j == 'country':\n",
    "                country.append(z)\n",
    "\n",
    "keys_countries, counts_countries = np.unique(country, return_counts=True)\n",
    "country_counts = pd.DataFrame({'keys':keys_countries,'counts':counts_countries})\n",
    "country_counts = country_counts.sort_values(by='counts', ascending=False)\n",
    "sns.barplot(data=country_counts[country_counts['counts'] > 1000],x='counts',y='keys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent = []\n",
    "for i,k in zip(df['add_type'],df['country_adj']):\n",
    "    if i != None:\n",
    "        for j,z in zip(i,k):\n",
    "            if j == 'continent':\n",
    "                continent.append(z)\n",
    "\n",
    "keys_continent, counts_continent = np.unique(continent, return_counts=True)\n",
    "continent_counts = pd.DataFrame({'keys':keys_continent,'counts':counts_continent})\n",
    "continent_counts = continent_counts.sort_values(by='counts', ascending=False)\n",
    "sns.barplot(data=continent_counts,x='counts',y='keys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset finalisation\n",
    "\n",
    "In the next section, information on which continent each country belongs to is saved, thanks to geopy and pycountry. Subsequently, information is saved in the dataset in this way:\n",
    "- One column contains only the countries\n",
    "- One the continents, either when information on the continent alone is found in the abstract, or when the continent is extracted from the country\n",
    "- Waters, i.e. rivers and streams\n",
    "- Oceans, seas and gulfs\n",
    "\n",
    "The relevant coordinates are also saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to get country code with geopy from coordinates, and then the continent of each country thanks to pycountry\n",
    "def get_country_code_from_coordinates(coordinates,country, attempt=1, max_attempts=5):\n",
    "    latitude, longitude = coordinates\n",
    "    try:\n",
    "        location = geolocator.reverse((latitude, longitude), language=\"en\")\n",
    "    except GeopyError:\n",
    "        if attempt <= max_attempts:\n",
    "            time.sleep(1.1)\n",
    "            return get_country_code_from_coordinates(coordinates,country, attempt=attempt+1)\n",
    "    # Extract country code (ISO 3166-1 alpha-2 code) from the location address\n",
    "    if location == None:\n",
    "        missing_class = country\n",
    "        country_code = None\n",
    "    else:\n",
    "        country_code = (location.raw.get('address', {}).get('country_code', None))\n",
    "        if country_code == None:\n",
    "            missing_class = country\n",
    "        else:\n",
    "            country_code = country_code.upper()\n",
    "            missing_class = None\n",
    "    \n",
    "    return country_code, missing_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_code = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual mapping of countries for which pycountry mapping fails\n",
    "countries_code['Palestinian Territories'] = 'PS'\n",
    "countries_code['Kosovo'] = 'KS' #ISO not existant\n",
    "countries_code['Andaman'] = 'IN'\n",
    "countries_code['Nicobar'] = 'IN'\n",
    "countries_code['Signy Island'] = 'AQ'\n",
    "countries_code['South Orkney Islands'] = 'AQ'\n",
    "countries_code['Penguin Island'] = 'AU'\n",
    "countries_code['Ascension and Tristan da Cunha'] = 'GB'\n",
    "countries_code['Torgersen Island'] = 'AQ'\n",
    "countries_code['Sahrawi Arab Democratic Republic'] = 'EH'\n",
    "countries_code['Horseshoe Island'] = 'AQ'\n",
    "countries_code['Scholander Island'] = 'AQ'\n",
    "countries_code['Ross Island'] = 'AQ'\n",
    "countries_code['Caroline Islands'] = 'FM'\n",
    "countries_code['Alectoria Island'] = 'AQ'\n",
    "countries_code['Weertman Island'] = 'AQ'\n",
    "countries_code['Smith Island'] = 'US'\n",
    "countries_code['Marguerite Bay'] = 'AQ'\n",
    "countries_code['Shelikhov Gulf'] = 'RU'\n",
    "countries_code['Petermann Island'] = 'AQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the continent for each country\n",
    "missing = {}\n",
    "for country_l, coord_l, add_type_l in tqdm(zip(df['country_adj'], df['coord_adj'], df['add_type'])):\n",
    "    if country_l != None:\n",
    "        for country, coord, add_type in zip(country_l,coord_l,add_type_l):\n",
    "            if country not in countries_code and country not in missing:\n",
    "                if add_type == 'country':\n",
    "                    try:\n",
    "                        countries_code[country] = pc.country_name_to_country_alpha2(country)\n",
    "                    except KeyError:\n",
    "                        missing[country] = [coord,add_type]\n",
    "                elif add_type in ['continent','ocean','sea','bay']:\n",
    "                    break\n",
    "                elif country == 'Antarctica':\n",
    "                    countries_code[country] = \"AQ\"\n",
    "                else:\n",
    "                    code, missing_class = get_country_code_from_coordinates(coord,country)\n",
    "                    if missing_class:\n",
    "                        missing[missing_class] = [coord,add_type]\n",
    "                    else:\n",
    "                        countries_code[country] = code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the locations in countries, continents, rivers and streams, oceans amd seas\n",
    "country_only = []\n",
    "continent_only = []\n",
    "ocean_sea_bay = []\n",
    "coord_waters = []\n",
    "for country_l,coord_l, add_type_l in tqdm(zip(df['country_adj'],df['coord_adj'], df['add_type'])):\n",
    "    if country_l != None:\n",
    "        countries = []\n",
    "        continents = []\n",
    "        waters = []\n",
    "        coord_w = []\n",
    "        for country, coord, add_type in zip(country_l,coord_l,add_type_l):\n",
    "            if country in countries_code:\n",
    "                if countries_code[country] == 'AQ':\n",
    "                    countries.append('Antarctica')\n",
    "                    continents.append('Antarctica')\n",
    "                elif countries_code[country] == 'KS':\n",
    "                    countries.append('Kosovo')\n",
    "                    continents.append('Europe')\n",
    "                elif countries_code[country] == 'TL':\n",
    "                    countries.append('Timor-Leste')\n",
    "                    continents.append('Oceania')\n",
    "                elif countries_code[country] == 'EH':\n",
    "                    countries.append('Western Sahara')\n",
    "                    continents.append('Africa')\n",
    "                else:\n",
    "                    countries.append(pc.country_alpha2_to_country_name(countries_code[country]))\n",
    "                    continents.append(pc.convert_continent_code_to_continent_name(pc.country_alpha2_to_continent_code(countries_code[country])))\n",
    "            elif add_type == 'continent':\n",
    "                continents.append(country)\n",
    "            else:\n",
    "                waters.append(country)\n",
    "                coord_w.append(coord)\n",
    "        if countries == []:\n",
    "            country_only.append(None)\n",
    "        else:\n",
    "            country_only.append(list(np.unique(countries)))\n",
    "        if continents == []:\n",
    "            continent_only.append(None)\n",
    "        else:\n",
    "            continent_only.append(list(np.unique(continents)))\n",
    "        if waters == []:\n",
    "            ocean_sea_bay.append(None)\n",
    "            coord_waters.append(None)\n",
    "        else:\n",
    "            ocean_sea_bay.append(list(np.unique(waters)))\n",
    "            coord_waters.append(coord_w)\n",
    "    else:\n",
    "        country_only.append(None)\n",
    "        continent_only.append(None)\n",
    "        ocean_sea_bay.append(None)\n",
    "        coord_waters.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean_sea_bay_un = []\n",
    "for i in ocean_sea_bay:\n",
    "    if i != None:\n",
    "        for j in i:\n",
    "            ocean_sea_bay_un.append(j)\n",
    "np.unique(ocean_sea_bay_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_only_un = []\n",
    "for i in continent_only:\n",
    "    if i != None:\n",
    "        for j in i:\n",
    "            continent_only_un.append(j)\n",
    "np.unique(continent_only_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_only_un = []\n",
    "for i in country_only:\n",
    "    if i!=None:\n",
    "        for j in i:\n",
    "            country_only_un.append(j)\n",
    "np.unique(country_only_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to get coordinates from locations\n",
    "def geolocate_coord(country, attempt=0, max_attempt=5):\n",
    "    try:\n",
    "        location = geolocator.geocode(country, language='en')\n",
    "    except GeopyError:\n",
    "        time.sleep(1.1)\n",
    "        if attempt < max_attempt:\n",
    "            location = geolocate_coord(country, attempt=attempt+1)\n",
    "        elif attempt == max_attempt:\n",
    "            time.sleep(10)\n",
    "            location = geolocate_coord(country)\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting coordinates from countries\n",
    "coord_countries = {}\n",
    "for i in tqdm(list(np.unique(country_only_un))):\n",
    "    if i == 'Taiwan, Province of China':\n",
    "        j = 'Taiwan'\n",
    "        location = geolocate_coord(j)\n",
    "        coord_countries[i] = (location.latitude, location.longitude) \n",
    "    else:\n",
    "        location = geolocate_coord(i)\n",
    "        coord_countries[i] = (location.latitude, location.longitude)\n",
    "coord_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting coordinates for continents\n",
    "coord_continents = {}\n",
    "for i in tqdm(list(np.unique(continent_only_un))):\n",
    "    location = geolocate_coord(i)\n",
    "    coord_continents[i] = (location.latitude, location.longitude) \n",
    "coord_continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attaching information to the dataset\n",
    "df['country_only'] = country_only\n",
    "df['continent'] = continent_only\n",
    "df['Ocean_Sea_Bay'] = ocean_sea_bay\n",
    "df['waters_coord'] = coord_waters\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing coordinates for countries to attach them to the dataset\n",
    "coord_countr_col = []\n",
    "for i in df['country_only']:\n",
    "    if i != None:\n",
    "        coord = []\n",
    "        for j in i:\n",
    "            coord.append(coord_countries[j])\n",
    "        coord_countr_col.append(coord)\n",
    "    else:\n",
    "        coord_countr_col.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing coordinates for continents to attach them to the dataset\n",
    "coord_cont_col = []\n",
    "for i in df['continent']:\n",
    "    if i != None:\n",
    "        coord = []\n",
    "        for j in i:\n",
    "            coord.append(coord_continents[j])\n",
    "        coord_cont_col.append(coord)\n",
    "    else:\n",
    "        coord_cont_col.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['coord_countr'] = coord_countr_col\n",
    "df['coord_cont'] = coord_cont_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_geo_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset with keywords \n",
    "df_kw = pd.read_csv('df_fe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the keywords in the dataset with geographical information\n",
    "df['keywords'] = df_kw['key_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the final dataset\n",
    "df.to_csv('final_geo_kw.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
